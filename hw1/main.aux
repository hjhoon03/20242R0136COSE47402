\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\newlabel{preliminaries}{{}{1}{2. Preliminaries}{section*.1}{}}
\newlabel{data-manipulation}{{}{1}{2.1. Data Manipulation}{section*.2}{}}
\newlabel{getting-start}{{}{1}{2.1.1. Getting Start}{section*.3}{}}
\newlabel{indexing-and-slicing}{{}{2}{2.1.2. Indexing and Slicing}{section*.4}{}}
\newlabel{operations}{{}{3}{2.1.3. Operations}{section*.5}{}}
\newlabel{broadcasting}{{}{3}{2.1.4. Broadcasting}{section*.6}{}}
\newlabel{saving-memory}{{}{4}{2.1.5. Saving Memory}{section*.7}{}}
\newlabel{conversion-to-other-python-objects}{{}{4}{2.1.6. Conversion to Other Python Objects}{section*.8}{}}
\newlabel{summary}{{}{5}{2.1.7. Summary}{section*.9}{}}
\newlabel{exercises}{{}{5}{2.1.8. Exercises}{section*.10}{}}
\newlabel{data-preprocessing}{{}{5}{2.2. Data Preprocessing}{section*.11}{}}
\newlabel{reading-the-dataset}{{}{5}{2.2.1. Reading the Dataset}{section*.12}{}}
\newlabel{data-preparation}{{}{6}{2.2.2. Data Preparation}{section*.13}{}}
\newlabel{conversion-to-the-tensor-format}{{}{6}{2.2.3. Conversion to the Tensor Format}{section*.14}{}}
\newlabel{discussion}{{}{7}{2.2.4. Discussion}{section*.15}{}}
\newlabel{linear-algebra}{{}{7}{2.3. Linear Algebra}{section*.16}{}}
\newlabel{scalars}{{}{7}{2.3.1. Scalars}{section*.17}{}}
\newlabel{vectors}{{}{7}{2.3.2. Vectors}{section*.18}{}}
\newlabel{matrices}{{}{7}{2.3.3. Matrices}{section*.19}{}}
\newlabel{tensors}{{}{8}{2.3.4. Tensors}{section*.20}{}}
\newlabel{basic-properties-of-tensor-arithmetic}{{}{8}{2.3.5. Basic Properties of Tensor Arithmetic}{section*.21}{}}
\newlabel{reduction}{{}{9}{2.3.6. Reduction}{section*.22}{}}
\newlabel{non-reduction-sum}{{}{9}{2.3.7. Non-Reduction Sum}{section*.23}{}}
\newlabel{dot-products}{{}{10}{2.3.8. Dot Products}{section*.24}{}}
\newlabel{matrix-vector-products}{{}{10}{2.3.9. Matrix-Vector Products}{section*.25}{}}
\newlabel{matrix-matrix-multiplication}{{}{10}{2.3.10. Matrix-Matrix Multiplication}{section*.26}{}}
\newlabel{norms}{{}{10}{2.3.11. Norms}{section*.27}{}}
\newlabel{discussion}{{}{11}{2.3.12. Discussion}{section*.28}{}}
\newlabel{exercises}{{}{11}{2.3.13. Exercises}{section*.29}{}}
\newlabel{automatic-differentiation}{{}{13}{2.5. Automatic Differentiation}{section*.30}{}}
\newlabel{a-simple-function}{{}{13}{2.5.1. A Simple Function}{section*.31}{}}
\newlabel{backward-for-non-scalar-variables}{{}{14}{2.5.2. Backward for Non-Scalar Variables}{section*.32}{}}
\newlabel{detaching-computation}{{}{14}{2.5.3. Detaching Computation}{section*.33}{}}
\newlabel{gradients-and-python-control-flow}{{}{15}{2.5.4. Gradients and Python Control Flow}{section*.34}{}}
\newlabel{discussion}{{}{15}{2.5.5. Discussion}{section*.35}{}}
\newlabel{exercises}{{}{15}{2.5.6. Exercises}{section*.36}{}}
\newlabel{linear-neural-networks-for-regression}{{}{17}{3. Linear Neural Networks for Regression}{section*.37}{}}
\newlabel{linear-regression}{{}{17}{3.1. Linear Regression}{section*.38}{}}
\newlabel{vectorization-for-speed}{{}{17}{3.1.2. Vectorization for Speed}{section*.39}{}}
\newlabel{the-normal-distribution-and-squared-loss}{{}{17}{3.1.3. The Normal Distribution and Squared Loss}{section*.40}{}}
\newlabel{object-oriented-design-for-implementation}{{}{18}{3.2. Object-Oriented-Design for Implementation}{section*.41}{}}
\newlabel{utilities}{{}{18}{3.2.1. Utilities}{section*.42}{}}
\newlabel{models}{{}{20}{3.2.2. Models}{section*.43}{}}
\newlabel{data}{{}{21}{3.2.3. Data}{section*.44}{}}
\newlabel{training}{{}{22}{3.2.4. Training}{section*.45}{}}
\newlabel{summary}{{}{22}{3.2.5. Summary}{section*.46}{}}
\newlabel{linear-regression-implementation-from-scratch}{{}{22}{3.4. Linear Regression Implementation from Scratch}{section*.47}{}}
\newlabel{defining-the-model}{{}{23}{3.4.1. Defining the Model}{section*.48}{}}
\newlabel{defining-the-loss-function}{{}{23}{3.4.2. Defining the Loss Function}{section*.49}{}}
\newlabel{defining-the-optimization-algorithm}{{}{23}{3.4.3. Defining the Optimization Algorithm}{section*.50}{}}
\newlabel{training}{{}{23}{3.4.4. Training}{section*.51}{}}
\newlabel{summary}{{}{25}{3.4.5. Summary}{section*.52}{}}
\newlabel{linear-neural-networks-for-classification}{{}{25}{4. Linear Neural Networks for Classification}{section*.53}{}}
\newlabel{softmax-regression}{{}{25}{4.1. Softmax Regression}{section*.54}{}}
\newlabel{classification}{{}{25}{4.1.1. Classification}{section*.55}{}}
\newlabel{linear-model}{{}{25}{4.1.1.1. Linear Model}{section*.56}{}}
\@writefile{toc}{\contentsline {paragraph}{4.1.1.1. Linear Model}{25}{section*.56}\protected@file@percent }
\newlabel{the-softmax}{{}{25}{4.1.1.2. The Softmax}{section*.57}{}}
\@writefile{toc}{\contentsline {paragraph}{4.1.1.2. The Softmax}{25}{section*.57}\protected@file@percent }
\newlabel{vectorization}{{}{25}{4.1.1.3. Vectorization}{section*.58}{}}
\@writefile{toc}{\contentsline {paragraph}{4.1.1.3. Vectorization}{25}{section*.58}\protected@file@percent }
\newlabel{loss-function}{{}{26}{4.1.2. Loss Function}{section*.59}{}}
\newlabel{log-likelihood}{{}{26}{4.1.2.1. Log-Likelihood}{section*.60}{}}
\@writefile{toc}{\contentsline {paragraph}{4.1.2.1. Log-Likelihood}{26}{section*.60}\protected@file@percent }
\newlabel{softmax-and-cross-entropy-loss}{{}{26}{4.1.2.2. Softmax and Cross-Entropy \mbox {} Loss}{section*.61}{}}
\@writefile{toc}{\contentsline {paragraph}{4.1.2.2. Softmax and Cross-Entropy \mbox  {} Loss}{26}{section*.61}\protected@file@percent }
\newlabel{information-theory-basics}{{}{27}{4.1.3. Information Theory Basics}{section*.62}{}}
\newlabel{entropy}{{}{27}{4.1.3.1. Entropy}{section*.63}{}}
\@writefile{toc}{\contentsline {paragraph}{4.1.3.1. Entropy}{27}{section*.63}\protected@file@percent }
\newlabel{summary-and-discussion}{{}{27}{4.1.4. Summary and Discussion}{section*.64}{}}
\newlabel{the-image-classification}{{}{27}{4.2. The Image Classification}{section*.65}{}}
\newlabel{loading-the-dataset}{{}{28}{4.2.1. Loading the Dataset}{section*.66}{}}
\newlabel{reading-a-minibatch}{{}{28}{4.2.2. Reading a Minibatch}{section*.67}{}}
\newlabel{visualization}{{}{29}{4.2.3. Visualization}{section*.68}{}}
\newlabel{summary}{{}{29}{4.2.4. Summary}{section*.69}{}}
\newlabel{the-base-classification}{{}{29}{4.3. The Base Classification}{section*.70}{}}
\newlabel{the-classifier-class}{{}{29}{4.3.1. The Classifier Class}{section*.71}{}}
\newlabel{accuracy}{{}{30}{4.3.2. Accuracy}{section*.72}{}}
\newlabel{summary}{{}{30}{4.3.3. Summary}{section*.73}{}}
\newlabel{softmax-regression-implementation-from-scratch}{{}{30}{4.4. Softmax Regression Implementation from Scratch}{section*.74}{}}
\newlabel{the-softmax}{{}{30}{4.4.1. The Softmax}{section*.75}{}}
\newlabel{the-model}{{}{30}{4.4.2. The Model}{section*.76}{}}
\newlabel{the-cross-entropy-loss}{{}{31}{4.4.3. The Cross-Entropy Loss}{section*.77}{}}
\newlabel{training}{{}{31}{4.4.4. Training}{section*.78}{}}
\newlabel{prediction}{{}{32}{4.4.5. Prediction}{section*.79}{}}
\newlabel{summary}{{}{32}{4.4.6. Summary}{section*.80}{}}
\newlabel{multilayer-perceptrons}{{}{33}{5. Multilayer Perceptrons}{section*.81}{}}
\newlabel{multilayer-perceptrons}{{}{33}{5.1. Multilayer Perceptrons}{section*.82}{}}
\newlabel{hidden-layers}{{}{33}{5.1.1. Hidden Layers}{section*.83}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces image.png}}{33}{figure.caption.84}\protected@file@percent }
\newlabel{limitations-of-linear-models}{{}{33}{5.1.1.1. Limitations of Linear \mbox {} Models}{section*.85}{}}
\@writefile{toc}{\contentsline {paragraph}{5.1.1.1. Limitations of Linear \mbox  {} Models}{33}{section*.85}\protected@file@percent }
\newlabel{incorporating-hidden-layers}{{}{33}{5.1.1.2. Incorporating Hidden \mbox {} Layers}{section*.86}{}}
\@writefile{toc}{\contentsline {paragraph}{5.1.1.2. Incorporating Hidden \mbox  {} Layers}{33}{section*.86}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces image.png}}{34}{figure.caption.87}\protected@file@percent }
\newlabel{from-linear-to-nonlinear}{{}{34}{5.1.1.3. From Linear to \mbox {} Nonlinear}{section*.88}{}}
\@writefile{toc}{\contentsline {paragraph}{5.1.1.3. From Linear to \mbox  {} Nonlinear}{34}{section*.88}\protected@file@percent }
\newlabel{activation-functions}{{}{35}{5.1.2. Activation Functions}{section*.89}{}}
\newlabel{relu-function}{{}{35}{5.1.2.1. ReLU Function}{section*.90}{}}
\@writefile{toc}{\contentsline {paragraph}{5.1.2.1. ReLU Function}{35}{section*.90}\protected@file@percent }
\newlabel{sigmoid-function}{{}{36}{5.1.2.2. Sigmoid Function}{section*.91}{}}
\@writefile{toc}{\contentsline {paragraph}{5.1.2.2. Sigmoid Function}{36}{section*.91}\protected@file@percent }
\newlabel{tanh-function}{{}{37}{5.1.2.3. Tanh Function}{section*.92}{}}
\@writefile{toc}{\contentsline {paragraph}{5.1.2.3. Tanh Function}{37}{section*.92}\protected@file@percent }
\newlabel{summary-and-discussion}{{}{38}{5.1.3. Summary and Discussion}{section*.93}{}}
\newlabel{implementation-of-multilayer-perceptrons}{{}{38}{5.2. Implementation of Multilayer Perceptrons}{section*.94}{}}
\newlabel{implementation-from-scratch}{{}{38}{5.2.1. Implementation from Scratch}{section*.95}{}}
\newlabel{initializing-model-parameters}{{}{38}{5.2.1.1. Initializing Model \mbox {} Parameters}{section*.96}{}}
\@writefile{toc}{\contentsline {paragraph}{5.2.1.1. Initializing Model \mbox  {} Parameters}{38}{section*.96}\protected@file@percent }
\newlabel{model}{{}{38}{5.2.1.2. Model}{section*.97}{}}
\@writefile{toc}{\contentsline {paragraph}{5.2.1.2. Model}{38}{section*.97}\protected@file@percent }
\newlabel{training}{{}{39}{5.2.1.3. Training}{section*.98}{}}
\@writefile{toc}{\contentsline {paragraph}{5.2.1.3. Training}{39}{section*.98}\protected@file@percent }
\newlabel{concise-implementation}{{}{39}{5.2.2. Concise Implementation}{section*.99}{}}
\newlabel{model}{{}{39}{5.2.2.1. Model}{section*.100}{}}
\@writefile{toc}{\contentsline {paragraph}{5.2.2.1. Model}{39}{section*.100}\protected@file@percent }
\newlabel{training}{{}{39}{5.2.2.2. Training}{section*.101}{}}
\@writefile{toc}{\contentsline {paragraph}{5.2.2.2. Training}{39}{section*.101}\protected@file@percent }
\newlabel{summary}{{}{40}{5.2.3. Summary}{section*.102}{}}
\newlabel{exercises}{{}{40}{5.2.4. Exercises}{section*.103}{}}
\newlabel{forward-propagation-backward-propagation-and-computational-graphs}{{}{42}{5.3. Forward Propagation, Backward Propagation, and Computational Graphs}{section*.104}{}}
\newlabel{forward-propagation}{{}{42}{5.3.1. Forward Propagation}{section*.105}{}}
\newlabel{computational-graph-of-forward-propagation}{{}{43}{5.3.2. Computational Graph of Forward propagation}{section*.106}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces image.png}}{43}{figure.caption.107}\protected@file@percent }
\newlabel{backpropagation}{{}{43}{5.3.3. Backpropagation}{section*.108}{}}
\newlabel{training-neural-networks}{{}{44}{5.3.4. Training Neural Networks}{section*.109}{}}
\newlabel{summary}{{}{45}{5.3.5. Summary}{section*.110}{}}
\gdef \@abspage@last{45}
